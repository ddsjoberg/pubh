---
title: "Regression Examples"
author: "Josie Athens"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    number_sections: yes
    fig_height: 5
    fig_width: 6
vignette: >
  %\VignetteIndexEntry{Regression Examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", message = FALSE, warning = FALSE)
```

# Introduction

The aim of this vignette is to illustrate the use/functionality of the `glm_coef` function. `glm_coef` can be used to display model coefficients with confidence intervals and p-values. The advantages and limitations of `glm_coef` are:

1. Recognises the main models used in epidemiology/public health.
2. Automatically back transforms estimates and confidence intervals, when the model requires it.
3. Can use robust standard errors for the calculation of confidence intervals.
    - Standard errors are used by default.
    - The use of standard errors is restricted by the following classes of objects (models): `gee`, `glm` and `survreg`.
4. Can display nice labels for the names of the parameters.
5. Returns a data frame that can be modified and/or exported as tables for publications (with further editing).

We start by loading relevant packages and setting alignment in `pander` tables (as suggested in the Template of this package):

```{r, message=FALSE}
library(pubh, warn.conflicts = FALSE)
library(car, warn.conflicts = FALSE)
library(descr, warn.conflicts = FALSE)
library(multcomp, warn.conflicts = FALSE)
library(pander, warn.conflicts = FALSE)
library(visreg, warn.conflicts = FALSE)

set.alignment("right", row.names = "left", permanent = TRUE)
```


# Multiple Linear Regression

For continuous outcomes there is no need of exponentiating the results.

```{r, message=FALSE}
data(birthwt)
birthwt$smoke <- factor(birthwt$smoke, labels=c("Non-smoker", "Smoker"))
birthwt$race <- factor(birthwt$race > 1, labels=c("White", "Non-white"))
model_norm <- glm(bwt ~ smoke + race, data = birthwt)
```

Traditional output from the model:

```{r}
pander(Anova(model_norm))
```

```{r}
pander(summary(model_norm))
```

Table of coefficients:

```{r}
glm_coef(model_norm)
```

Once we know the order in which the parameters are displayed, we can add labels to our final table:

> **Note:** Compare results using naive and robust standard errors.

```{r}
pander(glm_coef(model_norm, labels=c("Constant", "Smoker - Non-smoker", "Non-white - White"),
                se.rob = FALSE), split.table=Inf, caption="Table of coeffients using naive 
       standard errors.")
```


```{r}
pander(glm_coef(model_norm, labels=c("Constant", "Smoker - Non-smoker", "Non-white - White")),
       split.table=Inf, caption="Table of coeffients using robust standard errors.")
```

Effect plot:

```{r}
visreg(model_norm, "smoke", by = "race", overlay = TRUE, band = FALSE, partial = FALSE, 
       rug = FALSE, ylab = "Birth weight (g)", xlab = "Smoking status")
```


# Logistic Regression

For logistic regression we are interested in the odds ratios.

```{r}
data(diet, package = "Epi")
model_binom <- glm(chd ~ fibre, data = diet, family = binomial)
```

```{r}
pander(glm_coef(model_binom, labels = c("Constant", "Fibre intake (g/day)")), split.table=Inf,
       caption="Parameter estimates from logistic regression.")
```

Effect plot:

```{r}
visreg(model_binom, "fibre", scale = "response", band = FALSE, rug = FALSE,
       ylab = "P (CHD)", xlab = "Fibre (g/day)")
```


## Matched Case-Control Studies: Condtional Logistic Regression

```{r}
data(bdendo, package = "Epi")
levels(bdendo$gall) <- c("No GBD", "GBD")
levels(bdendo$est) <- c("No oestrogen", "Oestrogen")
```

```{r}
model_clogit <- clogit(d ~ est * gall + strata(set), data = bdendo)
glm_coef(model_clogit)
```

```{r}
pander(glm_coef(model_clogit, labels = c("Oestrogen/No oestrogen", "GBD/No GBD", 
                                         "Oestrogen:GBD Interaction")), 
       split.table = Inf, caption = "Parameter estimates from conditional logistic regression.")
```

Effect plot:

```{r}
visreg(model_clogit, "gall", by = "est", xlab="Gall blader disease", ylab="P (cancer)", 
       overlay = TRUE, rug = FALSE, band = FALSE, partial = FALSE, trans = inv_logit)
```


## Ordinal Logistic Regression

```{r}
library(ordinal, warn.conflicts = FALSE)
data(housing)
model_clm <- clm(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
glm_coef(model_clm)
```

```{r}
labs_ord <- c("Constant: Low/Medium satisfaction",
              "Constant: Medium/High satisfaction",
              "Perceived influence: Medium/Low",
              "Perceived influence: High/Low",
              "Accommodation: Apartment/Tower",
              "Accommodation: Atrium/Tower",
              "Accommodation: Terrace/Tower",
              "Afforded: High/Low")
pander(glm_coef(model_clm, labels = labs_ord), split.table = Inf,
       caption = "Parameter estimates on satisfaction of householders.")
```

> **Note:** In tne previous table parameter estimates and confidene intervals for *Perceived influence* and *Accommodation* were not adjusted for multiple comparisons. See example from **Poisson Regression** to see how to include adjusted parameters.

## Multinomial Regression

```{r, message=FALSE}
library(nnet)
model_multi <- multinom(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
```

```{r}
glm_coef(model_multi)
```


# Poisson Regression

For Poisson regression we are interested in incidence rate ratios.

```{r}
data(quine)
levels(quine$Eth) <- list(White = "N", Aboriginal = "A")
levels(quine$Sex) <- list(Male = "M", Female = "F")
model_pois <- glm(Days ~ Eth + Sex + Age, family = poisson, data = quine)
glm_coef(model_pois)
```

## Negative-binomial

The assumption is that the mean is equal than the variance. Is that the case?

```{r}
pander(estat(~ Days|Eth, data = quine, label = "Days of school absences"), split.table=Inf)
```

> **Note:** Look at the relative dispersion (coefficient of variation), for the variance to be equal to the means the CV would have to be about 35%.

More formally the following calculation should be close to 1:

```{r}
deviance(model_pois) / df.residual(model_pois)
```

Thus, we have over-dispersion. One option is to use a negative binomial distribution.

```{r}
model_negbin <- glm.nb(Days ~ Eth + Sex + Age, data = quine)
unadj <- glm_coef(model_negbin, labels=c("Constant",
                                   "Race: Aboriginal/White",
                                   "Sex: Female/Male",
                                   "F1/Primary",
                                   "F2/Primary",
                                   "F3/Primary"))
```

Notice that age group is a factor with more than two levels and is significant:

```{r}
pander(Anova(model_negbin))
```

Thus, we want to report confidence intervals and $p$-values adjusted for multiple comparisons.

The unadjusted CIs:

```{r}
pander(unadj, split.table=Inf, caption = "Parameter estimates with unadjusted CIs and p-values.")
```

Effect plot:

```{r}
visreg(model_negbin, "Age", by = "Eth", scale = "response", rug = FALSE, band = FALSE)
```


## Adjusting CIs and p-values for multiple comparisons

We adjust for multiple comparisons:

```{r, message=FALSE}
model_glht <- glht(model_negbin, linfct  = mcp(Age = "Tukey"))
age_glht <- xymultiple(model_glht, Exp = TRUE, plot = FALSE)
```

We can see the comparison graphically with:

```{r, fig.cap="Parameter estimates on the effect of age group on the number of days absent from school. Bars represent 95% CIs adjusted by the method of Westfall for multiple comparisons."}
xymultiple(model_glht, Exp = TRUE)
```

We use this information to construct the final table:

```{r}
final <- unadj
final[, 5] <- as.character(final[, 5])
age_glht[, 5] <- as.character(age_glht[, 5])
final[4:6, 3:5] <- age_glht[1:3, 3:5]
```

```{r}
pander(final, split.table=Inf, caption = "Parameter estimates. CIs and p-values for age group were adjusted 
       for multiple comparisons by the method of Westfall.")
```

# Survival Analysis

```{r}
data(bladder)
bladder$times <- bladder$stop
bladder$rx <- factor(bladder$rx, labels=c("Placebo", "Thiotepa"))
```

## Parametric method

```{r}
model_surv <- survreg(Surv(times, event) ~ rx, data = bladder)
```

Using robust standard errors (default):

```{r}
glm_coef(model_surv)
```

```{r}
pander(glm_coef(model_surv, labels = c("Treatment: Thiotepa/Placebo", "Scale")),
       split.table = Inf)
```

In this example the scale parameter is not statistically different from one, meaning hazard is constant and thus, we can use the exponential distribution:

```{r}
model_exp <- survreg(Surv(times, event) ~ rx, data = bladder, dist = "exponential")
pander(glm_coef(model_exp, labels = "Treatment: Thiotepa/Placebo"),
       split.table = Inf)
```

> **Interpretation:** Patients receiving Thiotepa live on average 64% more than those in the Placebo group.

Using naive standard errors:

```{r}
pander(glm_coef(model_exp, se.rob = FALSE, labels = "Treatment: Thiotepa/Placebo"),
       split.table = Inf)
```

Effect plot:

```{r}
visreg(model_exp, "rx", partial = FALSE, rug = FALSE, ylab = "Survival time", 
       xlab = "Treatment")
```


## Cox proportional hazards regression

```{r}
model_cox <-  coxph(Surv(times, event) ~ rx, data = bladder)
```

```{r}
pander(glm_coef(model_cox, labels = c("Treatment: Thiotepa/Placebo")), split.table = Inf)
```

> **Interpretation:** Patients receiving Thiotepa are 64% less likely of dying than those in the Placebo group.

Effect plot:

```{r}
visreg(model_cox, "rx", partial = FALSE, trans = exp, rug = FALSE,
       ylab = "Hazard", xlab = "Treatment")
```


# Mixed Linear Regression Models

## Continuous outcomes

```{r}
library(nlme, warn.conflicts = FALSE)
data(Orthodont)
```

```{r}
model_lme <- lme(distance ~ Sex*I(age - mean(age, na.rm = TRUE)), random=~1|Subject, 
                 method="ML", data=Orthodont)
glm_coef(model_lme)
```

```{r}
pander(glm_coef(model_lme, labels = c("Constant", "Sex: female-male", "Age (years)", 
                                      "Sex:Age interaction")), split.table=Inf)
```

```{r}
visreg(model_lme, "age", by = "Sex", overlay = TRUE, xlab = "Age (years)", ylab = "Distance (mm)")
```

```{r}
library(gee, warn.conflicts = FALSE)
model_gee_norm <- gee(distance ~ Sex*I(age - mean(age, na.rm = TRUE)), id = Subject, 
                      data = Orthodont, corstr = "AR-M")
```

For GEE models, robust standard errors are used by default:

```{r}
pander(glm_coef(model_gee_norm, labels = c("Constant", "Sex: female-male", "Age (years)", 
                                      "Sex:Age interaction")), split.table=Inf)
```

## Count outcomes

```{r}
data(Thall)

c1 <- cbind(Thall[, c(1:5)], count = Thall$y1)[, c(1:4, 6)]
c2 <- cbind(Thall[, c(1:4, 6)], count = Thall$y2)[, c(1:4, 6)]
c3 <- cbind(Thall[, c(1:4, 7)], count = Thall$y3)[, c(1:4, 6)]
c4 <- cbind(Thall[, c(1:4, 8)], count = Thall$y3)[, c(1:4, 6)]
epilepsy <- rbind(c1, c2, c3, c4)
```

```{r results = "hide"}
model_gee <- gee(count ~ treat + base + I(age - mean(age, na.rm = TRUE)), id = factor(id), 
                 data = epilepsy, family = poisson, corstr = "exchangeable", scale.fix = TRUE)
```

```{r}
pander(glm_coef(model_gee, labels = c("Constant", "Treatment (Prograbide/Control)", 
                               "Baseline count", "Age (years)")), split.table = Inf)
```


Using `glmer`:

```{r results = "hide"}
library(lme4, warn.conflicts = FALSE)
model_glmer <- glmer(count ~ treat + base + I(age - mean(age, na.rm = TRUE)) + 
                       (1|id), data=epilepsy, family=poisson)
```

```{r}
pander(glm_coef(model_glmer, labels = c("Constant", "Treatment (Prograbide/Control)", 
                               "Baseline count", "Age (years)")), split.table = Inf)
```


Do we may have over-dispersion?

```{r}
pander(estat(~ count|treat, data = epilepsy, label = "Number of seizures"))
```

Scaling the variance:

```{r results = "hide"}
model_quasi <- gee(count ~ treat + base + I(age - mean(age, na.rm = TRUE)), id = factor(id), 
                 data = epilepsy, family = quasi(variance = "mu^2", link = "log"), 
                 corstr = "exchangeable")
```

```{r}
pander(glm_coef(model_quasi, labels = c("Constant", "Treatment (Prograbide/Control)", 
                               "Baseline count", "Age (years)")), split.table = Inf)
```

